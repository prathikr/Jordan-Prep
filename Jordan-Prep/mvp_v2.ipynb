{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "np.random.seed(2017) # set random seed value to get reproducible results\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTROLS\n",
    "\n",
    "grouping = 'stimulants'\n",
    "#grouping = 'opioids'\n",
    "\n",
    "outcome = 'engage30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(865, 34)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engage30</th>\n",
       "      <th>female_cd</th>\n",
       "      <th>unemplmt_cd</th>\n",
       "      <th>prsatx_cd</th>\n",
       "      <th>TRIg_0_cd</th>\n",
       "      <th>TMIg_0_cd</th>\n",
       "      <th>SESg_0_cd</th>\n",
       "      <th>gvsg_cd</th>\n",
       "      <th>und15_cd</th>\n",
       "      <th>CWSg_0_cd</th>\n",
       "      <th>srprobg_cd</th>\n",
       "      <th>dldiag_cd</th>\n",
       "      <th>dssg_0_cd</th>\n",
       "      <th>epsg_0_cd</th>\n",
       "      <th>adhdg_0_cd</th>\n",
       "      <th>cdsg_0_cd</th>\n",
       "      <th>suicprbs_0_cd</th>\n",
       "      <th>cjsig_0_cd</th>\n",
       "      <th>lrig_0_cd</th>\n",
       "      <th>srig_0_cd</th>\n",
       "      <th>homeless_0_cd</th>\n",
       "      <th>S6_cd</th>\n",
       "      <th>gcsg_0_cd</th>\n",
       "      <th>ncar_cd</th>\n",
       "      <th>SFSg_0_cd</th>\n",
       "      <th>B2a_0g</th>\n",
       "      <th>Raceg4_cd_gr_1</th>\n",
       "      <th>Raceg4_cd_gr_2</th>\n",
       "      <th>Raceg4_cd_gr_3</th>\n",
       "      <th>Raceg4_cd_gr_4</th>\n",
       "      <th>pop_deng</th>\n",
       "      <th>%_unemployedg</th>\n",
       "      <th>%_public_assistanceg</th>\n",
       "      <th>%_povertyg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    engage30  female_cd  unemplmt_cd  prsatx_cd  TRIg_0_cd  TMIg_0_cd  \\\n",
       "24         1          0            1          0          1          1   \n",
       "35         1          0            1          0          1          1   \n",
       "36         0          0            0          1          0          1   \n",
       "40         1          0            1          1          1          1   \n",
       "42         1          0            1          0          1          1   \n",
       "\n",
       "    SESg_0_cd  gvsg_cd  und15_cd  CWSg_0_cd  srprobg_cd  dldiag_cd  dssg_0_cd  \\\n",
       "24          0        1         1          0           2          1          0   \n",
       "35          0        0         0          0           1          1          1   \n",
       "36          1        2         1          0           1          1          2   \n",
       "40          0        2         1          0           2          1          1   \n",
       "42          1        2         1          0           1          1          0   \n",
       "\n",
       "    epsg_0_cd  adhdg_0_cd  cdsg_0_cd  suicprbs_0_cd  cjsig_0_cd  lrig_0_cd  \\\n",
       "24          1           0          0              0           2          2   \n",
       "35          1           1          0              0           2          2   \n",
       "36          1           2          0              0           1          2   \n",
       "40          1           2          2              0           2          2   \n",
       "42          1           2          0              0           2          1   \n",
       "\n",
       "    srig_0_cd  homeless_0_cd  S6_cd  gcsg_0_cd  ncar_cd  SFSg_0_cd  B2a_0g  \\\n",
       "24          2              0      1          0        0          2       1   \n",
       "35          1              1      1          0        0          2       1   \n",
       "36          2              1      1          0        1          0       1   \n",
       "40          1              0      1          2        0          0       2   \n",
       "42          0              1      1          0        0          0       2   \n",
       "\n",
       "    Raceg4_cd_gr_1  Raceg4_cd_gr_2  Raceg4_cd_gr_3  Raceg4_cd_gr_4  pop_deng  \\\n",
       "24               1               0               0               0       1.0   \n",
       "35               1               0               0               0       1.0   \n",
       "36               1               0               0               0       1.0   \n",
       "40               1               0               0               0       1.0   \n",
       "42               1               0               0               0       1.0   \n",
       "\n",
       "    %_unemployedg  %_public_assistanceg  %_povertyg  \n",
       "24            1.0                   2.0         1.0  \n",
       "35            1.0                   1.0         1.0  \n",
       "36            1.0                   2.0         1.0  \n",
       "40            1.0                   2.0         1.0  \n",
       "42            1.0                   1.0         1.0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(grouping + '.csv', index_col=[0]) # read in patient data\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast socioeconomic data as integers\n",
    "\n",
    "df = df.astype({'pop_deng': 'int64', '%_unemployedg': 'int64', '%_public_assistanceg': 'int64', '%_povertyg': 'int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(865, 33)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['epsg_0_cd'], inplace=True) # since dssg and epsg are correlated\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    628\n",
       "1    237\n",
       "Name: engage30, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[outcome].value_counts() # 1 represents a patient who did not engage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes (648, 32) (217, 32) (648,) (217,)\n",
      "Training set outcome counts:\n",
      "    engage30\n",
      "0       474\n",
      "1       174\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=[outcome])\n",
    "y = df[outcome]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=2017)\n",
    "print('Dataset sizes', X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "print('Training set outcome counts:\\n', y_train.value_counts().to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsampled dataset sizes (948, 32) (217, 32) (948,) (217,)\n",
      "Upsampled training set outcome counts:\n",
      "    engage30\n",
      "1       474\n",
      "0       474\n"
     ]
    }
   ],
   "source": [
    "# upsample minority class ***in training data only*** to combat outcome class imbalance and small dataset\n",
    "\n",
    "train_data = pd.concat([X_train, y_train], axis=1) # combine training data back for resampling\n",
    "negative = train_data[train_data[outcome] == 0] # separate majority...\n",
    "positive = train_data[train_data[outcome] == 1] # ...and minority class\n",
    "\n",
    "# upsample minority\n",
    "pos_upsampled = resample(positive, \n",
    "                           replace=True, # sample with replacement\n",
    "                           n_samples=len(negative)) # match number in majority class\n",
    "\n",
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([negative, pos_upsampled])\n",
    "X_train = upsampled.drop(columns=[outcome])\n",
    "y_train = upsampled[outcome]\n",
    "\n",
    "print('Upsampled dataset sizes', X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "print('Upsampled training set outcome counts:\\n', y_train.value_counts().to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    f1 = metrics.f1_score(y_test, y_pred)\n",
    "    precision = metrics.precision_score(y_test, y_pred)\n",
    "    recall = metrics.recall_score(y_test, y_pred)\n",
    "    auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Test Set Accuracy:\", round(accuracy, 4))\n",
    "    print(\"Test Set F1:\", round(f1, 4))\n",
    "    print(\"Test Set Precision:\", round(precision, 4))\n",
    "    print(\"Test Set Recall:\", round(recall, 4))\n",
    "    print(\"Test Set AUC:\", round(auc, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.3, 'class_weight': 'balanced', 'max_iter': 500}\n",
      "Best Training Score: 0.665636313004734 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 600 out of 600 | elapsed:   12.6s finished\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 50 features per sample; expecting 52",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-6cd87b4aee3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_logisitc_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-45-c5cce143d8f3>\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(model, X_test, y_test)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \"\"\"\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0m\u001b[1;32m    287\u001b[0m                              % (X.shape[1], n_features))\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X has 50 features per sample; expecting 52"
     ]
    }
   ],
   "source": [
    "# takes about 30 seconds for stimulants\n",
    "\n",
    "def get_logistic_regression_features(X):\n",
    "    # one-hot encode all variables (except binary vars) to get hazards across groups, drop reference group\n",
    "    result = X.copy()\n",
    "    \n",
    "    for col in result.columns:\n",
    "        if not np.isin(result[col], [0, 1]).all(): # if non-binary\n",
    "            one_hot = pd.get_dummies(result[col], prefix=col)\n",
    "            one_hot = one_hot.loc[:, ~one_hot.columns.str.endswith('1')] # drop group and use as reference\n",
    "            result = result.drop(col,axis = 1)\n",
    "            result = pd.concat([result, one_hot], axis=1)\n",
    "    #print('Logistic Regression Features:', result.columns)\n",
    "    return result\n",
    "\n",
    "def train_logisitc_regression(X_train, y_train):\n",
    "    lr = LogisticRegression()\n",
    "        \n",
    "    # inverse strength of regularization\n",
    "    C = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "    # class weights (John knows more about what this does...)\n",
    "    class_weight = ['balanced', 'balanced_subsample', None]\n",
    "    # maximum iterations to perform before failing to converge\n",
    "    max_iter = [500, 1000, 5000, 10000]\n",
    "    \n",
    "    # Create the parameter grid\n",
    "    param_grid = {'C': C,\n",
    "                  'class_weight': class_weight,\n",
    "                  'max_iter': max_iter}\n",
    "    \n",
    "    CV_lr = GridSearchCV(estimator=lr, param_grid=param_grid, cv=5, verbose=1)\n",
    "    CV_lr.fit(X_train_lr, y_train)\n",
    "    \n",
    "    print('Best Parameters:', CV_lr.best_params_)\n",
    "    print('Best Training Score:', CV_lr.best_score_, '\\n')\n",
    "    return CV_lr.best_estimator_\n",
    "    \n",
    "    \n",
    "X_train_lr = get_logistic_regression_features(X_train)\n",
    "X_test_lr = get_logistic_regression_features(X_test)\n",
    "\n",
    "lr = train_logisitc_regression(X_train_lr, y_train)\n",
    "test_model(lr, X_test_lr, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haz_ratios = np.exp(lr.coef_[0])\n",
    "feature_importance_lr = pd.DataFrame({'feature': X_test_lr.columns, 'LR-Hazards': haz_ratios})\n",
    "feature_importance_lr['mag-from-1'] = abs(feature_importance_lr['LR-Hazards'] - 1)\n",
    "feature_importance_lr.sort_values(by='mag-from-1', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes about 13 hours for stimulants\n",
    "\n",
    "def train_random_forest(X_train, y_train):\n",
    "    rfc = RandomForestClassifier()\n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [100, 200, 500, 1000, 2000]\n",
    "    #n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = [None, 'log2', 'sqrt']\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [2, 5, 8, 10]\n",
    "    #max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "    max_depth.append(None)\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [5, 10, 15, 20]\n",
    "    #min_samples_leaf = [1, 2, 4]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True, False]\n",
    "    # class weights (John knows more about what this does...)\n",
    "    class_weight = ['balanced', 'balanced_subsample', None]\n",
    "    \n",
    "    # Create the parameter grid\n",
    "    param_grid = {'n_estimators': n_estimators,\n",
    "                  'max_features': max_features,\n",
    "                  'max_depth': max_depth,\n",
    "                  'min_samples_split': min_samples_split,\n",
    "                  'min_samples_leaf': min_samples_leaf,\n",
    "                  'bootstrap': bootstrap,\n",
    "                  'class_weight': class_weight}\n",
    "    \n",
    "    CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=5, verbose=1)\n",
    "    CV_rfc.fit(X_train, y_train)\n",
    "    print('Best Parameters:', CV_rfc.best_params_)\n",
    "    print('Best Score:', CV_rfc.best_score_)\n",
    "    return CV_rfc.best_estimator_\n",
    "    \n",
    "rfc = train_random_forest(X_train, y_train)\n",
    "test_model(rfc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# permutation importance\n",
    "\n",
    "result = permutation_importance(rfc, X_test, y_test, scoring='roc_auc', n_repeats=20)\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax.boxplot(result.importances[sorted_idx].T,\n",
    "           vert=False, labels=X_test.columns[sorted_idx])\n",
    "ax.set_title(\"Permutation Importances (test set)\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean decrease in impurity\n",
    "\n",
    "mdi = rfc.feature_importances_\n",
    "feature_importance_rf = pd.DataFrame({'feature': X_test.columns, 'RF-MDI': mdi})\n",
    "feature_importance_rf.sort_values(by='RF-MDI', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter('./raw_results/' + grouping + '_feature_importance.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Write each dataframe to a different worksheet.\n",
    "feature_importance_lr.to_excel(writer, sheet_name='LR')\n",
    "feature_importance_rf.to_excel(writer, sheet_name='RF')\n",
    "\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save test results\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"(%H:%M:%S)\")\n",
    "current_date = now.date().strftime(\"%b-%d\")\n",
    "\n",
    "filename = current_date + current_time + \".html\"\n",
    "print(\"saving results to \" + filename)\n",
    "os.system(\"ipython nbconvert --to html mvp_v2.ipynb\")\n",
    "os.rename('mvp_v2.html', \"./raw_results/\" + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
